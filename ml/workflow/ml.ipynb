{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "803cf980",
   "metadata": {},
   "source": [
    "# Convolutional Long Short Term Memory neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca00497",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fee0ea0",
   "metadata": {},
   "source": [
    "This notebook summarizes the **dataset**, the **ConvLSTM** model architecture, the current **training loop** used for predicting wildfire spread, and how we convert model probabilities on the grid into a pixel graph and adjacency matrix that will later feed a QUBO formulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d24dbddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9900bdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users\n"
     ]
    }
   ],
   "source": [
    "%cd ../..\n",
    "from ml.data.split_data import FireSpreadDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91c33cc",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac9a97b",
   "metadata": {},
   "source": [
    "The dataset used gathers satelite data from Google Earth. It is a time series of daily observations which have active fires and extra variables such as fuel, topography and weather conditions. It is available at [Zenodo](https://zenodo.org/records/8006177). It contains GeoTIFF files which will be used to train the proposed model. In the following picture it is displayed a specific tif with the fire that is captured and shown in band **23**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe7711d",
   "metadata": {},
   "source": [
    "<img src=\"../../images/tif.jpeg\" alt=\"Heatmap\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c3be3e",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685e24b7",
   "metadata": {},
   "source": [
    "A multivariate **spatio-temporal** model is implemented so as to make use of both temporal and spatial dependencies that are natural of the data. It takes into account the time frames because the fire spreding depends on the time we are looking at, and the spatial dimension because of the location of the fire spreading. The following architecture is used. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e536bf25",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "Time axis →\n",
    "t-(T-1)        t-(T-2)              ...                  t-1\n",
    "   │               │                                      │\n",
    "   ├──── Frame ────┼─────────────── … ────────────────────┤   (B, C, H, W)\n",
    "   ▼               ▼                                      ▼\n",
    "┌───────────────────────────────────────────────────────────────┐\n",
    "│                     ConvLSTM Layer 1                          │\n",
    "│  (process each time step; pass hidden state through time)     │\n",
    "└───────────────────────────────────────────────────────────────┘\n",
    "                               │ (per time step output h¹_t)\n",
    "                               ▼\n",
    "┌───────────────────────────────────────────────────────────────┐\n",
    "│                     ConvLSTM Layer 2                          │\n",
    "└───────────────────────────────────────────────────────────────┘\n",
    "                               │ (per time step output h²_t)\n",
    "                               ▼\n",
    "┌───────────────────────────────────────────────────────────────┐\n",
    "│                     ConvLSTM Layer 3                          │\n",
    "└───────────────────────────────────────────────────────────────┘\n",
    "                               │\n",
    "                         (take last time step output h³_t-1)\n",
    "                               ▼\n",
    "                    1×1 Conv (output head)\n",
    "                               ▼\n",
    "                      Next-frame map (B, 1, C, H, W)\n",
    "                          (e.g., fire probability)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3984da9e",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15960a05",
   "metadata": {},
   "source": [
    "After training the model, we get the heatmap of probabilites which are dispersed in the pixels of the frame. After, the adyacency matrix is used based on the prdictions of the model, which will be the input of QUBO."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96f007e",
   "metadata": {},
   "source": [
    "<img src=\"../../images/heat_map.png\" alt=\"Heatmap\" width=\"600\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
